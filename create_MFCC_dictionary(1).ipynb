{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# This jupyter notebook is for performing data manipulations on the raw data\n",
    "I have used MFCCs of each audio file as the features for my model. This notebook extracts the MFCCs and also handles data augmentation.\n",
    "\n",
    "## Loading Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import glob\n",
    "import librosa\n",
    "import librosa.display\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.pyplot import specgram\n",
    "import pandas as pd\n",
    "import os\n",
    "import IPython.display as ipd\n",
    "from tqdm import tqdm_notebook\n",
    "import IPython.display as ipd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Getting file paths of the audio files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "files = glob.glob(r\"D:\\Kaggle\\datasets\\emotion_small\\val/*.wav\")\n",
    "print(len(files)) #total number of audio files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Getting the csv file with file names and labels. I have used this dataframe as reference for storing the MFCCs. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(r\"D:\\Kaggle\\datasets\\emotion_small\\meld_val_small.csv\",encoding = 'utf-8')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Augmentation methods\n",
    "Data augmentation can increase model's robustness and also help in increasing the training data size when we only have access to a small dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def noise(data):\n",
    "    \"\"\"\n",
    "    Adding White Noise.\n",
    "    \"\"\"\n",
    "    # you can take any distribution from https://docs.scipy.org/doc/numpy-1.13.0/reference/routines.random.html\n",
    "    noise_amp = 0.05*np.random.uniform()*np.amax(data)   # more noise reduce the value to 0.5\n",
    "    data = data.astype('float64') + noise_amp * np.random.normal(size=data.shape[0])\n",
    "    return data\n",
    "    \n",
    "def shift(data):\n",
    "    \"\"\"\n",
    "    Random Shifting.\n",
    "    \"\"\"\n",
    "    s_range = int(np.random.uniform(low=-5, high = 5)*1000)  #default at 500\n",
    "    return np.roll(data, s_range)\n",
    "    \n",
    "def stretch(data, rate=0.8):\n",
    "    \"\"\"\n",
    "    Streching the Sound. Note that this expands the dataset slightly\n",
    "    \"\"\"\n",
    "    data = librosa.effects.time_stretch(data, rate)\n",
    "    return data\n",
    "    \n",
    "def pitch(data, sample_rate):\n",
    "    \"\"\"\n",
    "    Pitch Tuning.\n",
    "    \"\"\"\n",
    "    bins_per_octave = 12\n",
    "    pitch_pm = 2\n",
    "    pitch_change =  pitch_pm * 2*(np.random.uniform())   \n",
    "    data = librosa.effects.pitch_shift(data.astype('float64'), \n",
    "                                      sample_rate, n_steps=pitch_change, \n",
    "                                      bins_per_octave=bins_per_octave)\n",
    "    return data\n",
    "    \n",
    "def dyn_change(data):\n",
    "    \"\"\"\n",
    "    Random Value Change.\n",
    "    \"\"\"\n",
    "    dyn_change = np.random.uniform(low=-0.5 ,high=7)  # default low = 1.5, high = 3\n",
    "    return (data * dyn_change)\n",
    "    \n",
    "def speedNpitch(data):\n",
    "    \"\"\"\n",
    "    speed and Pitch Tuning.\n",
    "    \"\"\"\n",
    "    # you can change low and high here\n",
    "    length_change = np.random.uniform(low=0.8, high = 1)\n",
    "    speed_fac = 1.2  / length_change # try changing 1.0 to 2.0 ... =D\n",
    "    tmp = np.interp(np.arange(0,len(data),speed_fac),np.arange(0,len(data)),data)\n",
    "    minlen = min(data.shape[0], tmp.shape[0])\n",
    "    data *= 0\n",
    "    data[0:minlen] = tmp[0:minlen]\n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating a dictionary to store the MFCCs\n",
    "The code below creates a dictionary which stores the MFCCs of audio files after the neccessary data augmentations. This is done for easy dataloading in the future. The file names are used as keys."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dictionary(n_mfcc,df=df,augmentation = [],directory ='D:/Kaggle/datasets/emotion_small/val/' ):\n",
    "    sample_rate = 44100\n",
    "    dim = (n_mfcc,1 + int(np.floor((sample_rate * 3)/512)))\n",
    "    df_dict = {}\n",
    "    input_length = sample_rate * 3\n",
    "    \n",
    "    for i in tqdm_notebook(range(len(df))):\n",
    "        file_path = str(directory)+ '/' + str(df['fname'][i])\n",
    "        data, _ = librosa.load(file_path, res_type='kaiser_fast',duration=3,sr=22050*2,offset=0.5)\n",
    "        \n",
    "        # Random offset / Padding\n",
    "        if len(data) > input_length:\n",
    "            max_offset = len(data) - input_length\n",
    "            offset = np.random.randint(max_offset)\n",
    "            data = data[offset:(input_length+offset)]\n",
    "        else:\n",
    "            if input_length > len(data):\n",
    "                max_offset = input_length - len(data)\n",
    "                offset = np.random.randint(max_offset)\n",
    "            else:\n",
    "                offset = 0\n",
    "                \n",
    "            data = np.pad(data, (offset, input_length - len(data) - offset), \"constant\") #padding \n",
    "            \n",
    "            #Data augmentation\n",
    "            if(len(augmentation) != 0):\n",
    "                for aug in augmentation:\n",
    "                    if(aug == 'noise'):\n",
    "                        data = noise(data)\n",
    "                    elif(aug == 'shift'):\n",
    "                        data = shift(data)\n",
    "                    elif(aug == 'stretch'):\n",
    "                        data = stretch(data)\n",
    "                    elif(aug == 'pitch'):\n",
    "                        data = pitch(data)\n",
    "                    elif(aug == 'dyn_change'):\n",
    "                        data = dyn_change(data)\n",
    "                    elif(aug == 'speedNpitch'):\n",
    "                        data = speedNpitch(data)\n",
    "                    else:\n",
    "                        assert 1 == 0\n",
    "        S = librosa.feature.melspectrogram(data,sr = 44100)\n",
    "        log_S = librosa.power_to_db(S,ref = np.max)\n",
    "        #getting the MFCC values\n",
    "        mfcc = librosa.feature.mfcc(S = log_S, sr=sample_rate, n_mfcc= dim[0])\n",
    "        df_dict[str(df['fname'][i])] = mfcc   #storing the values in the dictionary with the file name as the key\n",
    "    return df_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Getting the MFCC dictionary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dict = get_dictionary(n_mfcc = 100,augmentation = [])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving the dictionary as a .npy file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('D:/Kaggle/datasets/emotion_small/mfcc_dictionaries/mfcc_val_small.npy',df_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
